<!DOCTYPE html>
<html lang="en-us">
<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<title>Metrics for assessing forecast accuracy</title>
<meta name="description" content="A website built through Hugo and blogdown.">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="robots" content="all,follow">
<meta name="googlebot" content="index,follow,snippet,archive">
<link rel="stylesheet" href="https://kathryntmorrison.github.io/pa/css/bootstrap.min.css">
<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Roboto:400,300,700,400italic">
<link rel="stylesheet" href="https://kathryntmorrison.github.io/pa/css/font-awesome.min.css">
<link rel="stylesheet" href="https://kathryntmorrison.github.io/pa/css/owl.carousel.css">
<link rel="stylesheet" href="https://kathryntmorrison.github.io/pa/css/owl.theme.css">


  <link href="https://kathryntmorrison.github.io/pa/css/style.default.css" rel="stylesheet" id="theme-stylesheet">


<link href="https://kathryntmorrison.github.io/pa/css/custom.css" rel="stylesheet">
<link rel="shortcut icon" href="https://kathryntmorrison.github.io/pa/img/favicon.png">



<script type="text/javascript"
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script></head>
<body>
  <div id="all">
      <div class="container-fluid">
          <div class="row row-offcanvas row-offcanvas-left">
              <div id="sidebar" class="col-xs-6 col-sm-4 col-md-3 sidebar-offcanvas">
  <div class="sidebar-content">
    <h1 class="sidebar-heading"><a href="../../../../">Precision Analytics</a></h1>
<p class="social">
  
  
  
  <a href="https://twitter.com/kathryn_tm" data-animate-hover="pulse" class="external twitter">
    <i class="fa fa-twitter"></i>
  </a>
  
  
  <a href="https://www.instagram.com/arf_hotel/" title="" class="external instagram">
    <i class="fa fa-instagram"></i>
  </a>
  
  
  <a href="mailto:morrison.kathrynt@gmail.com" data-animate-hover="pulse" class="email">
    <i class="fa fa-envelope"></i>
  </a>
  
  
  
  
  <a href="https://github.com/kathryntmorrison" data-animate-hover="pulse">
    <i class="fa fa-github"></i>
  </a>
  
</p>

    
    
    <ul class="sidebar-menu">
      
      
        <li><a href="https://kathryntmorrison.github.io/pa">Services</a></li>
      
        <li><a href="https://kathryntmorrison.github.io/paabout/">About us</a></li>
      
        <li><a href="https://kathryntmorrison.github.io/papublications/">Recent publications</a></li>
      
        <li><a href="https://kathryntmorrison.github.io/paconsult/">Projects</a></li>
      
    </ul>
    
    

<center> 
 <img src="../../../../ktm.jpg" align="center" height="310" >  </center>
<br>
 

    <div class="copyright">
      <p class="credit">
        
        



<hr>
<br>

Template by <a href="https://bootstrapious.com/free-templates" class="external">Bootstrapious.com</a>

<br>
Ported to Hugo by <a href="https://github.com/kishaningithub">Kishan B</a>
<br>
<br>
&copy;2017 Kathryn Morrison
      </p>
    </div>
  </div>
</div>

              
<div class="col-xs-12 col-sm-8 col-md-9 content-column white-background">
  <div class="small-navbar visible-xs">
  <button type="button" data-toggle="offcanvas" class="btn btn-ghost pull-left"> <i class="fa fa-align-left"> </i>Menu</button>
  <h1 class="small-navbar-heading"><a href="../../../../">Precision Analytics</a></h1>
</div>

  <div class="row">
    <div class="col-lg-8">
      <div class="content-column-content">
         <h1>Metrics for assessing forecast accuracy</h1>
         <p>There are a number of ways to summarize forecast accuracy across a forecast horizon, but I’ve come to realize recently how unclear it is which measure to use in which situation - and how non-standardized it is.</p>
<!--more-->
<p>Sometimes we have data with different units, sometimes we have data with the same units but hugely different scales, sometimes outliers, and so on. We often want a measure that isn’t hugely sensitive to outliers and is scale-independent (relative). But, if we have data with many zeros, many relative measures can be problematic.</p>
<p>There seem to really be two primary types of forecast accuracy metrics:</p>
<ol style="list-style-type: decimal">
<li><p>Comparison between the true observed value <span class="math inline">\(y_t\)</span> and the predicted value <span class="math inline">\(\hat{y_t}\)</span>, based on the error e.g., <span class="math inline">\(e_t = y_t - \hat{y_t}\)</span></p></li>
<li><p>Comparison between the accuracy of a proposed method (<span class="math inline">\(e_t\)</span> from above) and a baseline method, often a naive forecast such as the last available data point (random walk), or possibly adjusting for seasonal trends only.</p></li>
</ol>
<p>The second option provides more flexibility but also potentially complicates comparisons between multiple proposed models, and is less interpretable than say a percentage error.</p>
<p>The most commonly used metrics that fit into type (1) above are: <br></p>
<table>
<colgroup>
<col width="50%" />
<col width="49%" />
</colgroup>
<thead>
<tr class="header">
<th>Measure</th>
<th>Formula (for mean)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Mean (median) absolute error</td>
<td><span class="math display">\[\frac{1}{n}\sum \| e_t\| \]</span></td>
</tr>
<tr class="even">
<td>Mean (median) squared error</td>
<td><span class="math display">\[\frac{1}{n} \sum e_t^2\]</span></td>
</tr>
<tr class="odd">
<td>Root mean (median) squared error</td>
<td><span class="math display">\[\sqrt{ \frac{1}{n} \sum e_t^2}\]</span></td>
</tr>
<tr class="even">
<td>Mean (median) absolute percentage error</td>
<td><span class="math display">\[\frac{1}{n} \sum \| \frac{e_t} {y_t}\|\]</span></td>
</tr>
<tr class="odd">
<td>Symmetric mean (median) absolute percentage error</td>
<td><span class="math display">\[\frac{1}{n} \sum \frac{\| e_t\|} { \|y_t\| + \|\hat{y_t}\|}\]</span></td>
</tr>
</tbody>
</table>
<p><br></p>
<p>(I excluded the metrics based purely on ranking). <br> <br> <br></p>
<table style="width:100%;">
<colgroup>
<col width="16%" />
<col width="22%" />
<col width="27%" />
<col width="33%" />
</colgroup>
<thead>
<tr class="header">
<th>Measure</th>
<th>Robustness to outliers</th>
<th>Ability to address zeros</th>
<th>Comparisons across different scales</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>M(d)AE</td>
<td>Stable</td>
<td>Defined <span class="math inline">\(y_t \in R\)</span></td>
<td>Scale/unit dependent</td>
</tr>
<tr class="even">
<td>M(d)SE</td>
<td>Sensitive</td>
<td>Defined <span class="math inline">\(y_t \in R\)</span></td>
<td>Scale/unit dependent</td>
</tr>
<tr class="odd">
<td>RM(d)SE</td>
<td>Sensitive</td>
<td>Defined <span class="math inline">\(y_t \in R\)</span></td>
<td>Scale/unit dependent</td>
</tr>
<tr class="even">
<td>M(d)APE</td>
<td>Stable</td>
<td>Undefined if <span class="math inline">\(y = 0\)</span></td>
<td>Relative measure (%)</td>
</tr>
<tr class="odd">
<td>SM(d)APE</td>
<td>Stable</td>
<td>Undefined if <span class="math inline">\(y = \hat{y}\)</span></td>
<td>Relative measure (%)</td>
</tr>
</tbody>
</table>
<p><br></p>
<p>It’s both interesting and frustrating that there are no standard best practices. In fact, inappropriate metrics have been frequently used even in large prediction competitions!<span class="math inline">\(^1\)</span>.</p>
<p>In my dissertation, I have Poisson count data at different scales, sometimes different units, with outliers, and with zero-inflation. I am struggling to find the best metric! I will likely end up using a ratio of mean absolute error between two methods since I am comparing (i) multivariate models to univariate, and (ii) temporal models to spatio-temporal. Ideally though, I would prefer to find a more interpretable measure. I am wondering if I can standardize something similar to MAPE, but using an average across the forecast horizon as the denominator, rather than the original value. I imagine something like this:</p>
<p>Horizon-standardized MAPE <span class="math display">\[= \frac{1}{n} \sum_{i=1}^n \frac{\|y_i - \hat{y_i}\| }{ \frac{1}{n} \sum_{i=1}^n y_i } \]</span> <br></p>
<p>This denominator would not be zero except in degenerate cases, would be consistent across different models (whereas the window may change), and this would standardize each absolute measure of accuracy by the expected value across the horizon. This definitely has some interpretation limitations but I’m going to continue to think about it and maybe look at some really simple simulation studies.</p>
<p><br> <br> <br></p>
<hr />
<p><span class="math inline">\(^1\)</span> Hyndman, Rob J., and Anne B. Koehler. “Another look at measures of forecast accuracy.” <em>International Journal of Forecasting</em> 22.4 (2006): 679-688.</p>

         
      </div>
    </div>
  </div>
</div>

          </div>
      </div>
  </div>
  <script src="https://kathryntmorrison.github.io/pa/js/jquery.min.js"></script>
<script src="https://kathryntmorrison.github.io/pa/js/bootstrap.min.js"></script>
<script src="https://kathryntmorrison.github.io/pa/js/jquery.cookie.js"> </script>
<script src="https://kathryntmorrison.github.io/pa/js/ekko-lightbox.js"></script>
<script src="https://kathryntmorrison.github.io/pa/js/jquery.scrollTo.min.js"></script>
<script src="https://kathryntmorrison.github.io/pa/js/masonry.pkgd.min.js"></script>
<script src="https://kathryntmorrison.github.io/pa/js/imagesloaded.pkgd.min.js"></script>
<script src="https://kathryntmorrison.github.io/pa/js/owl.carousel.min.js"></script>
<script src="https://kathryntmorrison.github.io/pa/js/front.js"></script>

</body>
</html>
